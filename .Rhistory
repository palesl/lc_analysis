#dists|>ggplot(aes(x=k,y=Pr ))+geom_line( ) + facet_wrap(~parliament)
# now to calculate observed binomials
dists_observed<-bind_cols(parliament=NA, k = NA, Pr = NA,)
for(i in 1:47){
K <-data.frame(K=0:acts_for_test$enactments[i] )
probs_table<-  model_set$number_enactments[model_set$parliament==i] |>table()|>
as.data.frame()
probs_table$Var1<-probs_table$Var1|>as.character()|>as.numeric()
K<-K|>left_join(probs_table, by=join_by("K"=="Var1"))
K$Freq[is.na(K$Freq)]<-0
K$Freq[K$K==0]<-acts_for_test$on_books[i] - sum(K$Freq)
K$Freq[K$Freq<0]<-0
K$probs<-K$Freq/sum(K$Freq)
parl<-rep(i, nrow(K))
appender<-bind_cols(parliament=parl, k=K$K, Pr=K$probs)
dists_observed<-bind_rows(dists_observed, appender)
}
dists_observed<-dists_observed[!is.na(dists_observed$parliament),]
dists_observed<-dists_observed[dists_observed$parliament!=47,]
#dists_observed|>ggplot(aes(x=k,y=Pr ))+geom_line( ) + facet_wrap(~parliament)
## comparing variances of expected and observed distributions
dists_observed_sum<-dists_observed|>group_by(parliament)|>
summarise(obs_var=sum(Pr*k*(1-Pr)),
obs_mean=sum(Pr*k),
n=n())
dists_sum<-dists|>group_by(parliament)|>
summarise(exp_var=sum(Pr*k*(1-Pr)),
exp_mean=sum(Pr*k))
dists_sum<-dists_sum|>left_join(dists_observed_sum)
dists_sum$delta_mean<-dists_sum$obs_mean-dists_sum$exp_mean
plot0<-ggplot(dists_sum)+geom_line(aes(parliament, exp_var))+
geom_line(aes(parliament, obs_var), col="red")+
annotate(geom='text',label= expression(paste(italic(Var),"[",italic(X),"]"," ",(Expected))), x=21.2,y=.1, col= "black")+
annotate(geom='text',label=expression(paste(italic(Var),"[",italic(X),"]"," ",(Observed))), x=21,y=.9, col='red')+
geom_vline(xintercept = 1, lty=2,col='grey40')+
annotate(geom='text',label="converging", angle=90,x=2,y=1.3, col='grey40')+
geom_vline(xintercept = 4, lty=2,col='grey40')+
annotate(geom='text',label="binomial variance", angle=90,x=5,y=1.3, col='grey40')+
geom_vline(xintercept = 31, lty=2,col='grey40')+
annotate(geom='text',label="overdispersion", angle=90,x=32,y=1.3, col='grey40')+
theme_minimal()+ylab(expression(paste(italic(Var),"[",italic(X),"]")))+xlab("Parliament")+
scale_x_continuous(breaks = seq(1,46, 5))+
scale_y_continuous(limits=c(0,2))
plot0 # interesting overdispersion from parliament #30 ()
plot0mean<-ggplot(dists_sum)+geom_line(aes(parliament, exp_mean),linewidth = 2)+
geom_line(aes(parliament, obs_mean), col="red")+
annotate(geom='text',label= expression(paste(italic(E),"[",italic(X),"]"," ", (Expected))), x=23,y=.85, col= "black")+
annotate(geom='text',label= expression(paste(italic(E),"[",italic(X),"]"," ", (Observed))), x=23,y=0.1, col='red')+
theme_minimal()+ylab(expression(paste(italic(E),"[",italic(X),"]")))+xlab("Parliament")+
scale_x_continuous(breaks = seq(1,46, 5))+
scale_y_continuous(limits=c(0,2))
plot0mean
plot0mean
library(tidyverse)
# calculating the expected number of repeat enactments (simple binomial approach)
calculate_prob_distribution <- function(n_acts, amendments) {
n<-amendments
p<-1/n_acts
probabilities <- numeric(n + 1)
for (k in 0:n) {
probabilities[k+1]<- choose(n + k -1, k)*p^k*(1-p)^(n-k)
}
return(probabilities)
}
# Example usage
n_acts <- 4000  # total number of acts on the books
amendments<- 300 # Number of amendments made
# Calculate the probability distribution
prob_distribution <- calculate_prob_distribution(n_acts, amendments)
probs<-bind_cols(k=0:amendments, pr = prob_distribution)
probs$F<-cumsum(probs$pr)
pbinom(q=0:amendments,size=amendments,prob=1/n_acts)
# Print the results
ggplot(probs)+geom_col( aes(x=k,y=pr ))
# a really simple test using new acts, amendments, and repeals per parliament...
acts_on_the_books <- ausleg::alrc_as_made(prin_amend="Principal", leg_type = "Acts")
# new acts
new_acts<-acts_on_the_books|>group_by(parliament)|>
summarise(new_acts=n())|>
mutate(parliament=as.numeric(parliament))
# repeals
acts_on_the_books$repeal_parl<-NA
parls<-ausPH::getParliaments()
for(i in 1:nrow(parls)){
acts_on_the_books$repeal_parl[acts_on_the_books$repealDate>parls$DateElection[i]&
acts_on_the_books$repealDate<parls$ParliamentEnd[i]]<-i
}
acts_on_the_books$repeal_parl[is.na(acts_on_the_books$repeal_parl)]<-50
repeals<-acts_on_the_books|>group_by(repeal_parl)|>
summarise(repeals=n())|>
rename(parliament="repeal_parl")
# amendments
amendments<-amend_counts|>
group_by(parliament)|>
summarise(amendments=sum(number_enactments))|>
mutate(parliament=as.numeric(parliament))
# joining
acts_for_test<- new_acts|>left_join(repeals)|>left_join(amendments)|>
arrange(parliament)
acts_for_test$repeals[is.na(acts_for_test$repeals)]<-0
# creating running total
acts_for_test$on_books<-cumsum(acts_for_test$new_acts - acts_for_test$repeals)
# adding new_acts to amendments
enactments<-model_set|>group_by(parliament)|>
summarise(enactments=sum(number_enactments))
acts_for_test$enactments<-enactments$enactments
# creating theoretical binomial distributions...
dists<-bind_cols(parliament=NA, k = NA, Pr = NA,)
for(i in 1:47){
K<-0:acts_for_test$enactments[i]
probs<-dbinom(x=0:acts_for_test$enactments[i],
size=acts_for_test$enactments[i],
prob=1/acts_for_test$on_books[i])
parl<-rep(i, length(K))
appender<-bind_cols(parliament=parl, k=K, Pr=probs)
dists<-bind_rows(dists, appender)
}
dists<-dists[!is.na(dists$parliament),]
dists<-dists[dists$parliament!=47,]
View(dists)
library(tidyverse)
# calculating the expected number of repeat enactments (simple binomial approach)
calculate_prob_distribution <- function(n_acts, amendments) {
n<-amendments
p<-1/n_acts
probabilities <- numeric(n + 1)
for (k in 0:n) {
probabilities[k+1]<- choose(n + k -1, k)*p^k*(1-p)^(n-k)
}
return(probabilities)
}
# Example usage
n_acts <- 4000  # total number of acts on the books
amendments<- 300 # Number of amendments made
# Calculate the probability distribution
prob_distribution <- calculate_prob_distribution(n_acts, amendments)
probs<-bind_cols(k=0:amendments, pr = prob_distribution)
probs$F<-cumsum(probs$pr)
pbinom(q=0:amendments,size=amendments,prob=1/n_acts)
# Print the results
ggplot(probs)+geom_col( aes(x=k,y=pr ))
# a really simple test using new acts, amendments, and repeals per parliament...
acts_on_the_books <- ausleg::alrc_as_made(prin_amend="Principal", leg_type = "Acts")
# new acts
new_acts<-acts_on_the_books|>group_by(parliament)|>
summarise(new_acts=n())|>
mutate(parliament=as.numeric(parliament))
# repeals
acts_on_the_books$repeal_parl<-NA
parls<-ausPH::getParliaments()
for(i in 1:nrow(parls)){
acts_on_the_books$repeal_parl[acts_on_the_books$repealDate>parls$DateElection[i]&
acts_on_the_books$repealDate<parls$ParliamentEnd[i]]<-i
}
acts_on_the_books$repeal_parl[is.na(acts_on_the_books$repeal_parl)]<-50
repeals<-acts_on_the_books|>group_by(repeal_parl)|>
summarise(repeals=n())|>
rename(parliament="repeal_parl")
# amendments
amendments<-amend_counts|>
group_by(parliament)|>
summarise(amendments=sum(number_enactments))|>
mutate(parliament=as.numeric(parliament))
# joining
acts_for_test<- new_acts|>left_join(repeals)|>left_join(amendments)|>
arrange(parliament)
acts_for_test$repeals[is.na(acts_for_test$repeals)]<-0
# creating running total
acts_for_test$on_books<-cumsum(acts_for_test$new_acts - acts_for_test$repeals)
# adding new_acts to amendments
enactments<-model_set|>group_by(parliament)|>
summarise(enactments=sum(number_enactments))
acts_for_test$enactments<-enactments$enactments
# creating theoretical binomial distributions...
dists<-bind_cols(parliament=NA, k = NA, Pr = NA,)
for(i in 1:47){
K<-0:acts_for_test$enactments[i]
probs<-dbinom(x=0:acts_for_test$enactments[i],
size=acts_for_test$enactments[i],
prob=1/acts_for_test$on_books[i])
parl<-rep(i, length(K))
appender<-bind_cols(parliament=parl, k=K, Pr=probs)
dists<-bind_rows(dists, appender)
}
dists<-dists[!is.na(dists$parliament),]
dists<-dists[dists$parliament!=47,]
View(dists)
View(acts_for_test)
K <-data.frame(K=0:acts_for_test$enactments[i] )
K
i<-2
K <-data.frame(K=0:acts_for_test$enactments[i] )
K
probs_table<-  model_set$number_enactments[model_set$parliament==i] |>table()|>
as.data.frame()
probs_table
probs_table<-  model_set$number_enactments[model_set$parliament==i] |>table()|>
as.data.frame()
probs_table$Var1<-probs_table$Var1|>as.character()|>as.numeric()
probs_table
K<-K|>left_join(probs_table, by=join_by("K"=="Var1"))
K$Freq[is.na(K$Freq)]<-0
sum(K$Freq)
acts_for_test$on_books[i]
acts_for_test$on_books[i] - sum(K$Freq)
dists_observed<-bind_cols(parliament=NA, k = NA, Pr = NA,)
for(i in 1:47){
K <-data.frame(K=0:acts_for_test$enactments[i] )
probs_table<-  model_set$number_enactments[model_set$parliament==i] |>table()|>
as.data.frame()
probs_table$Var1<-probs_table$Var1|>as.character()|>as.numeric()
K<-K|>left_join(probs_table, by=join_by("K"=="Var1"))
K$Freq[is.na(K$Freq)]<-0
K$Freq[K$K==0]<-acts_for_test$on_books[i] - sum(K$Freq)
K$Freq[K$Freq<0]<-0
K$probs<-K$Freq/sum(K$Freq)
parl<-rep(i, nrow(K))
appender<-bind_cols(parliament=parl, k=K$K, Pr=K$probs)
dists_observed<-bind_rows(dists_observed, appender)
}
dists_observed<-dists_observed[!is.na(dists_observed$parliament),]
dists_observed<-dists_observed[dists_observed$parliament!=47,]
dists_observed_sum<-dists_observed|>group_by(parliament)|>
summarise(obs_var=sum(Pr*k*(1-Pr)),
obs_mean=sum(Pr*k),
n=n())
dists_sum<-dists|>group_by(parliament)|>
summarise(exp_var=sum(Pr*k*(1-Pr)),
exp_mean=sum(Pr*k))
dists_sum<-dists_sum|>left_join(dists_observed_sum)
dists_sum
dists_observed
View(dists_observed)
View(model_set)
probs_table<-  model_set$number_enactments[model_set$parliament==i] |>table()|>
as.data.frame()
probs_table
probs_table<-  model_set$number_enactments[model_set$parliament==i] |>table()|>
as.data.frame()
probs_table$Var1<-probs_table$Var1|>as.character()|>as.numeric()
probs_table
parl<-rep(i, nrow(K))
appender<-bind_cols(parliament=parl, k=K$K, Pr=K$probs)
dists_sum<-dists|>group_by(parliament)|>
summarise(exp_var=sum(Pr*k*(1-Pr)),
exp_mean=sum(Pr*k))
dists_sum<-dists|>group_by(parliament)|>
summarise(exp_var=sum(Pr*k*(1-Pr)),
exp_mean=sum(Pr*k))
dists_sum
# creating theoretical binomial distributions...
dists<-bind_cols(parliament=NA, k = NA, Pr = NA,)
for(i in 1:47){
K<-0:acts_for_test$enactments[i]
probs<-dbinom(x=0:acts_for_test$enactments[i],
size=acts_for_test$enactments[i],
prob=1/acts_for_test$enactments[i])
parl<-rep(i, length(K))
appender<-bind_cols(parliament=parl, k=K, Pr=probs)
dists<-bind_rows(dists, appender)
}
dists<-dists[!is.na(dists$parliament),]
dists<-dists[dists$parliament!=47,]
dists_observed<-bind_cols(parliament=NA, k = NA, Pr = NA,)
for(i in 1:47){
K <-data.frame(K=0:acts_for_test$enactments[i] )
probs_table<-  model_set$number_enactments[model_set$parliament==i] |>table()|>
as.data.frame()
probs_table$Var1<-probs_table$Var1|>as.character()|>as.numeric()
K<-K|>left_join(probs_table, by=join_by("K"=="Var1"))
K$Freq[is.na(K$Freq)]<-0
K$Freq[K$K==0]<-acts_for_test$on_books[i] - sum(K$Freq)
K$Freq[K$Freq<0]<-0
K$probs<-K$Freq/sum(K$Freq)
parl<-rep(i, nrow(K))
appender<-bind_cols(parliament=parl, k=K$K, Pr=K$probs)
dists_observed<-bind_rows(dists_observed, appender)
}
dists_observed<-dists_observed[!is.na(dists_observed$parliament),]
dists_observed<-dists_observed[dists_observed$parliament!=47,]
dists_observed_sum<-dists_observed|>group_by(parliament)|>
summarise(obs_var=sum(Pr*k*(1-Pr)),
obs_mean=sum(Pr*k),
n=n())
dists_sum<-dists|>group_by(parliament)|>
summarise(exp_var=sum(Pr*k*(1-Pr)),
exp_mean=sum(Pr*k))
dists_sum<-dists_sum|>left_join(dists_observed_sum)
dists_sum<-dists|>group_by(parliament)|>
summarise(exp_var=sum(Pr*k*(1-Pr)),
exp_mean=sum(Pr*k))
dists_sum
library(tidyverse)
# calculating the expected number of repeat enactments (simple binomial approach)
calculate_prob_distribution <- function(n_acts, amendments) {
n<-amendments
p<-1/n_acts
probabilities <- numeric(n + 1)
for (k in 0:n) {
probabilities[k+1]<- choose(n + k -1, k)*p^k*(1-p)^(n-k)
}
return(probabilities)
}
# Example usage
n_acts <- 4000  # total number of acts on the books
amendments<- 300 # Number of amendments made
# Calculate the probability distribution
prob_distribution <- calculate_prob_distribution(n_acts, amendments)
probs<-bind_cols(k=0:amendments, pr = prob_distribution)
probs$F<-cumsum(probs$pr)
pbinom(q=0:amendments,size=amendments,prob=1/n_acts)
# Print the results
ggplot(probs)+geom_col( aes(x=k,y=pr ))
# a really simple test using new acts, amendments, and repeals per parliament...
acts_on_the_books <- ausleg::alrc_as_made(prin_amend="Principal", leg_type = "Acts")
# new acts
new_acts<-acts_on_the_books|>group_by(parliament)|>
summarise(new_acts=n())|>
mutate(parliament=as.numeric(parliament))
# repeals
acts_on_the_books$repeal_parl<-NA
parls<-ausPH::getParliaments()
for(i in 1:nrow(parls)){
acts_on_the_books$repeal_parl[acts_on_the_books$repealDate>parls$DateElection[i]&
acts_on_the_books$repealDate<parls$ParliamentEnd[i]]<-i
}
acts_on_the_books$repeal_parl[is.na(acts_on_the_books$repeal_parl)]<-50
repeals<-acts_on_the_books|>group_by(repeal_parl)|>
summarise(repeals=n())|>
rename(parliament="repeal_parl")
# amendments
amendments<-amend_counts|>
group_by(parliament)|>
summarise(amendments=sum(number_enactments))|>
mutate(parliament=as.numeric(parliament))
# joining
acts_for_test<- new_acts|>left_join(repeals)|>left_join(amendments)|>
arrange(parliament)
acts_for_test$repeals[is.na(acts_for_test$repeals)]<-0
# creating running total
acts_for_test$on_books<-cumsum(acts_for_test$new_acts - acts_for_test$repeals)
# adding new_acts to amendments
enactments<-model_set|>group_by(parliament)|>
summarise(enactments=sum(number_enactments))
acts_for_test$enactments<-enactments$enactments
# creating theoretical binomial distributions...
dists<-bind_cols(parliament=NA, k = NA, Pr = NA,)
for(i in 1:47){
K<-0:acts_for_test$enactments[i]
probs<-dbinom(x=0:acts_for_test$enactments[i],
size=acts_for_test$enactments[i],
prob=1/acts_for_test$on_books[i])
parl<-rep(i, length(K))
appender<-bind_cols(parliament=parl, k=K, Pr=probs)
dists<-bind_rows(dists, appender)
}
dists<-dists[!is.na(dists$parliament),]
dists<-dists[dists$parliament!=47,]
#dists|>ggplot(aes(x=k,y=Pr ))+geom_line( ) + facet_wrap(~parliament)
# now to calculate observed binomials
dists_observed<-bind_cols(parliament=NA, k = NA, Pr = NA,)
for(i in 1:47){
K <-data.frame(K=0:acts_for_test$enactments[i] )
probs_table<-  model_set$number_enactments[model_set$parliament==i] |>table()|>
as.data.frame()
probs_table$Var1<-probs_table$Var1|>as.character()|>as.numeric()
K<-K|>left_join(probs_table, by=join_by("K"=="Var1"))
K$Freq[is.na(K$Freq)]<-0
K$Freq[K$K==0]<-acts_for_test$on_books[i] - sum(K$Freq)
K$Freq[K$Freq<0]<-0
K$probs<-K$Freq/sum(K$Freq)
parl<-rep(i, nrow(K))
appender<-bind_cols(parliament=parl, k=K$K, Pr=K$probs)
dists_observed<-bind_rows(dists_observed, appender)
}
dists_observed<-dists_observed[!is.na(dists_observed$parliament),]
dists_observed<-dists_observed[dists_observed$parliament!=47,]
#dists_observed|>ggplot(aes(x=k,y=Pr ))+geom_line( ) + facet_wrap(~parliament)
## comparing variances of expected and observed distributions
dists_observed_sum<-dists_observed|>group_by(parliament)|>
summarise(obs_var=sum(Pr*k*(1-Pr)),
obs_mean=sum(Pr*k),
n=n())
dists_sum<-dists|>group_by(parliament)|>
summarise(exp_var=sum(Pr*k*(1-Pr)),
exp_mean=sum(Pr*k))
dists_sum
View(eur_amends)
library(tidyverse)
# calculating the expected number of repeat enactments (simple binomial approach)
calculate_prob_distribution <- function(n_acts, amendments) {
n<-amendments
p<-1/n_acts
probabilities <- numeric(n + 1)
for (k in 0:n) {
probabilities[k+1]<- choose(n + k -1, k)*p^k*(1-p)^(n-k)
}
return(probabilities)
}
# Example usage
n_acts <- 4000  # total number of acts on the books
amendments<- 300 # Number of amendments made
# Calculate the probability distribution
prob_distribution <- calculate_prob_distribution(n_acts, amendments)
# inputting data from eu
eu_dat <- readRDS("data/amends/amends_01_model_data_EU.rds")
eu_sum<-eu_dat|>group_by(year)|>summarise(enactments=sum(n_enactments),
on_books=on_books[1])
# creating theoretical binomial distributions...
dists<-bind_cols(year=NA, k = NA, Pr = NA)
for(i in 1:nrow(eu_sum)){
K<-0:eu_sum$enactments[i]
probs<-dbinom(x=0:eu_sum$enactments[i],
size=eu_sum$enactments[i],
prob=1/eu_sum$on_books[i])
parl<-rep(eu_sum$year[i], length(K))
appender<-bind_cols(year=parl, k=K, Pr=probs)
dists<-bind_rows(dists, appender)
}
dists<-dists[!is.na(dists$year),]
#dists|>ggplot(aes(x=k,y=Pr ))+geom_line( ) + facet_wrap(~year)
# now to calculate observed binomials
dists_observed<-bind_cols(year=NA, k = NA, Pr = NA)
for(i in 1:nrow(eu_sum)){
K <-data.frame(K=0:eu_sum$enactments[i] )
probs_table<-  eu_dat[eu_dat$year==eu_sum$year[i],]
probs_table<-probs_table|>ungroup()|>select(enactments,n_enactments)
names(probs_table)<-c("Var1","Freq")
K<-K|>left_join(probs_table, by=join_by("K"=="Var1"))
K$Freq[is.na(K$Freq)]<-0
K$Freq[K$K==0]<-eu_sum$on_books[i] - sum(K$Freq[K$K!=0])
K$Freq[K$Freq<0]<-0
K$probs<-K$Freq/sum(K$Freq)
year<-rep(eu_sum$year[i], nrow(K))
appender<-bind_cols(year=year, k=K$K, Pr=K$probs)
dists_observed<-bind_rows(dists_observed, appender)
}
dists_observed<-dists_observed[!is.na(dists_observed$year),]
#dists_observed|>ggplot(aes(x=k,y=Pr ))+geom_line( ) + facet_wrap(~year)
## comparing variances of expected and observed distributions
dists_observed_sum<-dists_observed|>group_by(year)|>
summarise(obs_var=sum(Pr*k*(1-Pr)),
obs_mean=sum(Pr*k),
n=n())
dists_sum<-dists|>group_by(year)|>
summarise(exp_var=sum(Pr*k*(1-Pr)),
exp_mean=sum(Pr*k))
dists|>group_by(year)|>
mutate(exp_var=Pr*k*(1-Pr),
exp_mean=Pr*k)
dists_sum<-dists_sum|>left_join(dists_observed_sum)
dists_sum$delta_mean<-dists_sum$obs_mean-dists_sum$exp_mean
View(wide_dat)
# get acts and their amendments...
eur_leg <- evoeu::nodes|>filter(node_type=="Directives"|
node_type=="Regulations")|>
select(-key_id)
eur_amends<-evoeu::edges|>filter(edge_type=="Changes text in clause of"|
edge_type=="Replaces clause of"|
edge_type=="Adds text to clause of"|
edge_type=="Inserts new clause in"|
edge_type=="Repeals all or part of")|>
select(-key_id)
eur_leg<- eur_leg|>left_join(eur_amends, by=join_by('celex'=='incoming_celex'))
eur_leg_amends<-evoeu::nodes|>filter(node_type=="Directives"|
node_type=="Regulations")|>
select(celex,date)
names(eur_leg_amends)[2]<-'amend_date'
eur_leg<-eur_leg|>left_join(eur_leg_amends, by=join_by('outgoing_celex'=='celex'))
View(eur_leg)
query_directive<-elx_make_query(resource_type = c("directive"),
include_date_endvalid=T)
end_dates_directive<-elx_run_query(query_directive)
query_regulation<-elx_make_query(resource_type = c("regulation"),
include_date_endvalid=T)
end_dates_regulation<-elx_run_query(query_regulation)
end_dates<-bind_rows(end_dates_directive,end_dates_regulation)
# removing invalid dates
end_dates$dateendvalid[end_dates$dateendvalid=="1002-02-02"]<-NA
end_dates$dateendvalid<-as.Date(end_dates$dateendvalid)
end_dates_latest<-end_dates|>filter(!is.na(dateendvalid))|>
group_by(celex)|>
mutate(max_end_date=max(dateendvalid, na.rm = T))|>
summarise(max_end_date=max_end_date[1])
# adjoining
eur_leg<-eur_leg|>left_join(end_dates_latest)
eur_leg$repeal_year<-as.character(eur_leg$max_end_date)|>
substr(1,4)|>as.numeric()
eur_leg$repeal_year[is.na(eur_leg$repeal_year)]<-9999
eur_leg$amend_year<-as.character(eur_leg$amend_date)|>
substr(1,4)|>as.numeric()
eur_leg$enacted_year<-as.character(eur_leg$date)|>
substr(1,4)|>as.numeric()
amends <-eur_leg|>select(celex,enacted_year,amend_year,repeal_year)
amends$count<-1
duplicated(wide_dat$celex)
duplicated(wide_dat$celex)|>sort()
duplicated(wide_dat$celex)|>unique()
amends <-eur_leg|>select(celex,enacted_year,amend_year,repeal_year)
amends$count<-1
enacts<-amends|>select(celex,enacted_year, repeal_year, count)|>distinct()
enacts$amend_year<-enacts$enacted_year
#enacts and amends
pre_dat<-bind_rows(enacts,amends)
View(pre_dat)
rjson::fromJSON("https://github.com/Refugee-Law-Lab/legislation-fed-bulk-data/blob/main/DATA/df_acts_en.json")
rjson::fromJSON("~/Downloads/df_acts_en.json")
rjson::fromJSON(file="~/Downloads/df_acts_en.json")
canada<-rjson::fromJSON(file="~/Downloads/df_acts_en.json")
canada<-rjson::fromJSON(file="Users/pat/Downloads/df_acts_en.json")
canada<-rjson::fromJSON(file="~/Users/pat/Downloads/df_acts_en.json")
canada<-rjson::fromJSON(file="~/Downloads/df_acts_en.json")
